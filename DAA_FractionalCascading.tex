\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsfonts,amsmath,amssymb}
\usepackage[none]{hyphenat}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{float}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage[noline,boxed]{algorithm2e}
\usepackage[skins]{tcolorbox}
\usepackage[nottoc,notlot,notlof]{tocbibind}


\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyhead[L]{\slshape \MakeUppercase{}}
\fancyhead[R]{\slshape}
\fancyfoot[C]{\thepage}
%\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

%\parindent 0ex
\setlength{\parindent}{4em}
\setlength{\parskip}{0em}
\renewcommand{\baselinestretch}{1.5}

\begin{document}

\begin{titlepage}
\begin{center}
\vspace*{0.5cm}
\Large{\textbf{Design and Analysis of Algorithms}}\\
\Large{\textbf{Theory Project}}\\
\vfill
\line(1,0){400}\\[1mm]
\huge{\textbf{Fractional Cascading}}\\[3mm]
\Large{\textbf{An algorithmic approach}}\\[1mm]
\line(1,0){400}\\
\vfill
By \\ 
IMT2019051 Mani Nandadeep Medicharla \\
IMT2019063 R Prasannavenkatesh \\
IMT2019525 Vijay Jaisankar \\
\end{center}
\end{titlepage}

\tableofcontents
\thispagestyle{empty}
\clearpage
\setcounter{page}{1}

\section{Abstract}
        In this paper, we investigate the \textit{Fractional Cascading} technique in building range trees and for fast searching of an element in multiple arrays. In this venture, we introduce and examine \textit{Linear Search}, \textit{Binary Search}, \textit{Bridge Building} and \textit{Auxiliary lists}. We also look at some of the \textit{applications} of this technique, and suggest data structures for its efficient realisation. 

\section{Problem Statement}
\textit{Fractional cascading: }You are given an input of k ordered lists of numbers, each of size n as well as a query value x. The problem's output is
to return, for each list, True if the query value appears in the list and
False if it does not. For example, if the input is:
\begin{enumerate}[label=(\alph*)]
    \item List $L_1$: $[3,4,6]$
    \item List $L_2$: $[2,6,7]$
    \item List $L_3$: $[2,4,9]$
\end{enumerate}
and the query value is 4, then the expected output is [\textit{True},\textit{False},\textit{True}]. \\
\textbf{Give an algorithm to solve the fractional cascading problem.}



\section{Brute Force}
\subsection{Linear Search}

Linear search is the most basic search technique, wherein we sequentially compare each array element to the target element. In the worst case of the target element not coinciding with \textit{any} list element, the algorithm would reach the end of the list and we would report an unsuccessful search. \\
As each element is compared at most once, the time complexity is $O(n)$, where $n$ is the size of the list. \\ \\

This algorithm forms the basis of the simplest solution to our problem: We just run linear search on each of the $k$ lists. If we have $q$ queries, this takes $O(q \cdot k \cdot n)$ time, which is a lot and in real world situations, if $k$, $q$, and $n$ are even moderately large, the time taken would become astronomical. \\ 

\begin{tcolorbox}[blanker,width=(\linewidth-3.5cm)]
\begin{algorithm}[H]
    \SetAlgoLined
    \KwData{k arrays of size n and a query element x}
    \KwResult{Boolean array regarding whether element is present in the indiced array or not}
    
    \SetKwFunction{LinearSearch}{LinearSearch}
    \SetKwFunction{FMain}{Main}
    
    \SetKwProg{Fn}{Function}{:}{\KwRet \textit{False}}
    \Fn{\LinearSearch{Array,x}}
    {
        \For{$i\leftarrow 0$ \KwTo $n$}
        {
            \If{\textit{Array}[i] == x}
                {\KwRet \textit{True}\;}
        }
    }
    
    
    
    \SetKwProg{Fn}{Function}{:}{\KwRet 0}
    \Fn{\FMain}{
        output = [] \;
        \For{$i\leftarrow 0$ \KwTo $k$}
        {
            output.append(linearSearch(input[i],x);
        }
    }

% \caption{Brute Force method by doing k linear searches}
\end{algorithm}
\end{tcolorbox}

Note that, however, this approach does not take into account any relevant information given to us in the question which can speed up this algorithm. It is given that the \textit{lists are sorted}, so we can exploit this property and employ a faster searching technique to solve this problem in a better way: \textit{Binary Search}


%------------------------------------------------------------------------------%


\section{Improved Brute Force}
\subsection{Binary Search}



Binary search is another searching algorithm that works correctly only on sorted arrays. \\
It begins by comparing the target element with the element at the middle of the list. 
\begin{itemize}
    \item If they are equal, we have found the target in the list
    \item If the target is larger, and as the list is sorted, we must now turn our attention to the \textit{right half} of the list
    \item Similarly, if the target is smaller, we must focus on the \textit{left half} of the list.
\end{itemize}

In the worst case, Binary Search will take $O(\log n)$ comparisons, where n is the size of the list. \\ \\


To improve the performance of the Brute Force subroutine, we replace the Linear Search subroutine with the aforementioned Binary Search subroutine. If we have $q$ queries, this takes $O(q \cdot k \cdot \log n)$ time, which is certainly a lot better than the initial brute force algorithm, but can yet be improved further.

\begin{tcolorbox}[blanker,width=(\linewidth-3.5cm)]
\begin{algorithm}[H]
    \SetAlgoLined
    \KwData{k arrays of size n and a query element x}
    \KwResult{Boolean array regarding whether element is present in the indiced array or not}
    
    \SetKwFunction{BinarySearch}{BinarySearch}
    \SetKwFunction{FMain}{Main}
    
    \SetKwProg{Fn}{Function}{:}{\textbf{end Function}}
    \Fn{\BinarySearch{Array,x,left,right}}
    {
        \If{right $\geq$ left}{
            mid=$\frac{(left+right)}{2}$\;
            \If{Array[mid] == x}{
                \KwRet \textit{True}\;
            }
            \If{Array[mid] $>$ x}{
                BinarySearch(Array,x,left,mid-1)\;
            }
            \Else{
                BinarySearch(Array,x,mid+1,right)\;
            }  
        }
        \Else{
            \KwRet \textit{False}\;
        }
        
    }
    
    
    
    \SetKwProg{Fn}{Function}{:}{\KwRet 0}
    \Fn{\FMain}{
        output = [] \;
        \For{$i\leftarrow 0$ \KwTo $k$}
        {
            output.append(BinarySearch(input[i],x);
        }
    }

% \caption{Brute Force method by doing k linear searches}
\end{algorithm}
\end{tcolorbox}


%------------------------------------------------------------------------------%

\section{Bridge Building}
\subsection{Introduction to bridges}
A \textit{bridge} is a pointer from an element $a_i$ of $A_i$ to an element $a_j$ of $A_{i+1}$ where  $|a_i-a_j|$ is \textbf{small}, where $A$ is the list and $a$ represents an element of the array. By \textit{small}, we mean an element that is either of the same value, or with the smallest difference to the one considered as reference. \\ 

Once we locate the answer to a query in one array, we should be able to \textbf{follow a bridge} to a key that is close to the answer in the next array. \\
In the best case, we follow a bridge from the answer to the query in $A_i$ to a key in $A_{i+1}$ and then from there locate the answer in $A_{i+1}$, all in constant time. If we can do \textit{this},then once we have the answer in $A_1$ we can find the answer in the remaining $k-1$ sorted arrays in $O(k)$ time complexity. \\

From a technical standpoint, we \textit{implement} this method as follows: \\
For every element $e$ in the first array, give $e$ a pointer to the element with the \textit{same value} in the second array or if the value doesn't exist, the \textit{predecessor}. This is called bridge building between $A_i$ and $A_{i+1}$. Then, once we've found the item in the first array, we can just follow these pointers down in order to figure out where the item is in all the other arrays. To find the answer in $A_1$, we can just use a balanced binary search tree,thus making the overall time complexity of our algorithm $O(\log n + k)$ per query.







\subsection{Algorithm}
\begin{tcolorbox}[blanker,width=(\linewidth-3.5cm)]
\begin{algorithm}[H]
    \SetAlgoLined
    \KwData{k arrays of size n and a query element x}
    \KwResult{Boolean array regarding whether element is present in the indiced array or not}
    
    \SetKwFunction{BuildBridges}{BuildBridges}
    \SetKwFunction{FMain}{Main}
    
    \SetKwProg{Fn}{Function}{:}{\textbf{end Function}}
    \Fn{\BuildBridges{Array,x}}
    {
        \For{$i\leftarrow 0$ \KwTo $k-1$}{
            \For{$j\leftarrow 0$ \KwTo $n$}{
                Build bridge from Array[i][j] to Array[i+1][x] where $|$Array[i+1][y] - Array[i][j]$|$ is small. In this approach, if both predecessor and successor exists, then we take predecessor first.
            }
        }
    }
    
    
    \SetKwProg{Fn}{Function}{:}{\KwRet 0}
    \Fn{\FMain}{
        output = [] \;
        BuildBridges(input,x) \;
        output.append(BinarySearch(Array[i],x)) \;
        Once the element is found in the first array, follow the bridge path till the final array and append it to the output. \;
    }

% \caption{Brute Force method by doing k linear searches}
\end{algorithm}
\end{tcolorbox}
% \subsection{Proof of correctness}
\subsection{Shortcomings}

This method seems like a very interesting and efficient alternative to solve this problem. However, there are some glaring weaknesses to this approach, the most important one being the fact that certain classes of inputs render this method useless. \\
In particular, if a later list is completely \textit{in between} two elements of the first list, we have to redo the entire search, as the pointer pre-processing gives us no information that we didn't already know.

\textbf{Let's consider a simple example to elucidate this statement} \\
Consider the case where $k = 2$. Everything would be better if only we could guarantee that the first list contained the right elements to give you useful information about the second array. We could just merge the arrays, but if we did this in the general case we'd end up with a totally merged array of size kn, which is not so good if k is large.

Even if each time we find an answer in the sorted Array $A_i$, we follow the bridge pointer from it as well as from the key above it we are still left with the entire contents of catalog $A_{i+1}$ to search. This continues through the entire set of k catalogs.If we search each catalog by doing a linear scan from the point at which the bridge told us to begin,the total search time will be O(nk).Even if we build a balanced search tree over all elements in $A{i+1}$ that appear between two consecutive bridge pointers from $A_i$ the query time will still be O(klogn) which is similar to performing k binary searches to get the query element.



%------------------------------------------------------------------------------%
\section{Fractional Cascading}

\subsection{Intuition behind Fractional Cascading}
Because of the shortcomings of the \textit{Bridge Building} algorithm, i.e the case where every element of the "below array is in between all the elements of the "above" array.(\textbf{Note}: We say that array 1 is “above” array 2 and array 2 is “below” array 1. Therefore, an Array $j$ is below Array $i$ if $j > i$. In this case, we either have to do $k$ binary searches, or we have to merge all $n$ elements of the below array recursively and maintain bridges, to get the output. This will warrant a sub-optimal, extra time complexity of $O(k \cdot n)$, as we are going through \textit{each} array element iteratively to merge it.

To avoid this problem of merging all elements and getting $O(k \cdot n)$ time complexity, we start with the \textit{lowest} list in the sequence and select every $i$th element, where i = $\frac{1}{\alpha}$ and insert it into the array above it while still maintaining sorted order. \\
We then mark that element as \textit{promoted} and keep a pointer from it, to its original position in the bottom list. This operation of taking every $i$th element and \textit{promoting} it to the array above it is called \textit{cascading}, and since we are only promoting a fraction of the elements, the algorithm is called \textbf{fractional cascading}.

For selecting, $\alpha$, we can choose a variety of fractions, however $\alpha$ = $\frac{1}{2}$ seems most appropriate because, we will have to compare only 2 elements while searching, after prepocessing. This will also ensure that our time complexity stays low, and easily computable.


\subsection{Algorithmic Approach to Fractional Cascading}

Let the input be specified by $k$ $n$-element arrays, $A_1,A_2,\dots,A_k$, Let the query element value be $x$.
Let $M_1,M_2,\dots,M_k$ be the new \textit{merged arrays} such that $M_k = A_k$ and $\forall i < k$, $M_i$ is defined as the result of merging $M_i$ with every $\frac{1}{\alpha}$th element of $M_{i+1}$. \\ \\
As we're taking $\alpha$ = $\frac{1}{2}$, $M_i$ will be the result of merging $M_i$ with every alternate element of $M_{i+1}$. For every \textbf{cascaded element} of $M_i$ where i $<$ k, we keep two pointers from each element which are derived as follows:
\begin{itemize}
    \item If the element came from the same array, i.e, $A_i$, we keep a pointer to the two nearest neighbouring elements from $M_{i+1}$
    \item if the element has been cascaded, we keep a pointer to the predecessor of the element in $M_i$
\end{itemize}
These pointers helps to find the position of the query element x in $A_i$ and also in the cascaded arrays below in $O(1)$ time. \\ \\
\textbf{Note}: Since we are merging every alternate element of the below list to the current list, we have 
$|M_i| = |A_i| +\frac{1}{2}|M_{i+1}|$, which in turn ensures that $|A_i| \leq 2n = O(n)$. \\

After we perform the aforementioned pre-processing, querying $x$ in all $k$ lists is done as follows.
First, we make a query for x in $M_1$ using a binary search in $O(\log n)$. Once we have found the position of $x$ in $M_1$, we use the \textit{cascaded pointers} to find the position of x in $M_2$. Generalising this step, once we found the position of x in $M_i$ where i $<$ k, we use the cascaded pointers to find the position of x in $M_{i+1}$. \\ \\
To find the location in $M_{i+1}$, we find the \textit{two neighbouring elements} in $M_{i+1}$ that came from $M_i$ using the pointers we had assigned during the pre-processing phase. Now, these elements will have \textit{exactly one element} between them in $M_{i+1}$. \textbf{Therefore, to find the exact location in $M_{i+1}$, we just have to do a simple comparison with only the intermediate element}. This is the significance of taking $\alpha$ = $\frac{1}{2}$ as we just have to perform only one comparison, which takes $O(1)$ time, and hence we can retrieve the location of $x$ in $A_i$ from its location in $M_i$ again in $O(1)$ time. \\ \\

Hence, the time to perform the preprocessing for fractional cascading is O(nk), the total search time per query is $O(k+\log n)$ and, the total time taken by the Fractional Cascading algorithm is $O(q(k+\logn))$ for $q$ queries, which is an astronomical improvement over the previous algorithms.



% Define new lists $L'_1, . . . , L'_k$ by $L'_k$ = $L_k$, and for $i < k$, let $L'_i$ be the result of merging $L'_{i}$ with every other element of $L'_{i+1}$ Note that $|L'_i| = |L_i| +\frac{1}{2}|L'_{i+1}|$, so $|Li| \leq 2n = O(n).$. 
% For each $i < k$, keep two pointers from each element. If the element came from $L_i$, keep a pointer to the two neighboring elements from $L'_{i+1}$, and vice versa. These pointers allow us to take information of our placement in $L'_i$ and in O(1) turn it into information about our placement in $L_i$ and our placement in half of $L'_{i+1}$.
%Now to make a query for x in all k lists is quite straightforward. 
%First, query $L'_1$ for the location of x with a binary search. Now to find the location of x in $L'_{i+1}$ from the location of x in $L'_i$, find the two neighboring elements in $L'{i+1}$ that came from $L'_i$ using the extra pointers. Then these elements have exactly one element between them in $L'_{i+1}$. To find our actual location in $L'_{i+1}$, we simply do a comparison with that intermediate element. This allows us to turn the information about
%x’s location in $L'_i$ into information about x’s location in $L'_{i+1}$ in O(1) time, and we can retrieve x’s location in $L_i$ from its location in $L'_i$ in O(1), and thus we can query for x in all k lists in O(k + log n) time.


%------------------------------------------------------------------------------%


\section{Applications}
This technique has various applications in numerous fields. \\
\begin{enumerate}
    \item Computational Geometry
    \begin{itemize}
        \item Half-Range Plane Reporting
        \item Explicit Searching 
        \item Point Location
    \end{itemize}
    \item Networks
    \begin{itemize}
        \item Fast Packet filtering in internet routers.
        \item data distribution and retrieval in sensor networks
    \end{itemize}
    \item Linear Range Queries
        \begin{itemize}
            \item As an accompaniment to \textit{Segment Trees}
        \end{itemize}
\end{enumerate}


%------------------------------------------------------------------------------%

\pagebreak 
\begin{thebibliography}{}

\bibitem{Wikipedia Article}
\href{https://en.wikipedia.org/wiki/Fractional_cascading}{Wikipedia article on Fractional Cascading}

\bibitem{Fractional Cascading Demo}
\href{https://ravix339.github.io/FractionalCascading/}{Practical Demo Application to demonstrate Fraction cascading}

\bibitem{Opengenus Reference}
\href{https://iq.opengenus.org/fractional-cascading-in-binary-search/amp/}{Opengenus reference on Fraction Cascading}

\bibitem{Arbit Blog Essay}
\href{https://arpitbhayani.me/blogs/fractional-cascading}{An essay on fractional-cascading by arpit bhayani}

\end{thebibliography}

\end{document}
